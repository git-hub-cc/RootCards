import json
import os
import re

# ================= é…ç½®åŒºåŸŸ =================
SOURCE_FILE = 'middle.md'       # Aæ•°ç»„æºæ–‡ä»¶
FILTER_DIR = 'middle'           # Bæ•°ç»„æºç›®å½•ï¼ˆåŒ…å«å¾ˆå¤šjsonå’Œå­æ–‡ä»¶å¤¹ï¼‰
OUTPUT_FILE = 'remaining_words.txt'
# ===========================================

def extract_json_from_md(file_path):
    """
    è¯»å– .md æ–‡ä»¶ï¼Œæ¸…æ´— markdown æ ‡è®°å¹¶è§£æ JSON
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # å°è¯•æå–ä»£ç å—
        match = re.search(r'```(?:md|json)?\s*(.*?)```', content, re.DOTALL)
        json_str = match.group(1).strip() if match else content

        # ç®€å•çš„æ¸…ç†ï¼ˆé’ˆå¯¹ä¸è§„èŒƒçš„ç»“å°¾ï¼‰
        # å¦‚æœæ–‡ä»¶ç»“å°¾è¢«æˆªæ–­ï¼Œå°è¯•è¡¥å…¨ï¼ˆç®€å•çš„å°è¯•ï¼Œä¸ä¿è¯å®Œç¾ï¼‰
        if json_str.strip().endswith(','):
            json_str = json_str.strip()[:-1]

            # è§£æ
        # æ³¨æ„ï¼šå¦‚æœæ–‡ä»¶æˆªæ–­ä¸¥é‡ï¼Œè¿™é‡Œå¯èƒ½ä¼šæŠ›é”™ï¼Œéœ€è¦ç”¨æˆ·ä¿è¯middle.mdæ˜¯åˆæ³•çš„JSONç‰‡æ®µ
        try:
            data = json.loads(json_str)
        except json.JSONDecodeError:
            # æœ€åçš„æŒ£æ‰ï¼šå°è¯•æ‰‹åŠ¨è¡¥å…¨é—­åˆç¬¦å·
            try:
                data = json.loads(json_str + "]}]") # æ ¹æ®ä½ çš„æ–‡ä»¶ç»“æ„çŒœæµ‹
            except:
                print(f"âŒ è§£æ {file_path} å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶å†…å®¹æ˜¯å¦å®Œæ•´ï¼ˆæ‹¬å·æ˜¯å¦é—­åˆï¼‰ã€‚")
                return []

        # æå– words
        words = []
        deep_extract_words(data, words) # å¤ç”¨é€’å½’æå–é€»è¾‘
        return words

    except FileNotFoundError:
        print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶ {file_path}")
        return []

def deep_extract_words(data, collection):
    """
    é€’å½’æ·±å…¥ JSON çš„æ¯ä¸€å±‚ï¼Œå¯»æ‰¾å•è¯ã€‚
    ç­–ç•¥ï¼š
    1. å¦‚æœæ˜¯å­—å…¸ï¼Œæ‰¾ 'words' æˆ– 'word' é”®ã€‚
    2. å¦‚æœæ˜¯åˆ—è¡¨ï¼Œéå†å…ƒç´ ã€‚
    3. å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œæ”¶é›†å®ƒï¼ˆè§†æƒ…å†µè€Œå®šï¼Œè¿™é‡Œä¸»è¦æ”¶é›†åˆ—è¡¨é‡Œçš„å­—ç¬¦ä¸²ï¼‰ã€‚
    """
    if isinstance(data, dict):
        for key, value in data.items():
            # ç­–ç•¥ï¼šå¦‚æœé”®åæ˜¯ words, word, list, vocab ç­‰ï¼Œé‡ç‚¹æå–
            if key in ['words', 'word', 'vocabulary', 'list']:
                deep_extract_words(value, collection)
            else:
                # å¦åˆ™ç»§ç»­é€’å½’å¯»æ‰¾
                deep_extract_words(value, collection)

    elif isinstance(data, list):
        for item in data:
            if isinstance(item, str):
                # è¿‡æ»¤æ‰ä¸€äº›æ˜æ˜¾ä¸æ˜¯å•è¯çš„åƒåœ¾æ•°æ®ï¼ˆæ¯”å¦‚é•¿åº¦è¿‡é•¿çš„å¥å­ï¼‰
                if len(item) < 30 and " " not in item.strip():
                    collection.append(item)
            else:
                deep_extract_words(item, collection)

    # å¦‚æœ data æœ¬èº«å°±æ˜¯å­—ç¬¦ä¸²ï¼ˆåœ¨é€’å½’ä¸­è¢«ä¼ å…¥ï¼‰ï¼Œé€šå¸¸ç”± list å¾ªç¯å¤„ç†ï¼Œè¿™é‡Œä¸åšå¤„ç†

def load_words_from_directory_recursive(directory):
    """
    é€’å½’éå†ç›®å½•åŠå…¶å­ç›®å½•ä¸‹çš„æ‰€æœ‰ json æ–‡ä»¶
    """
    all_words = []
    file_count = 0

    if not os.path.exists(directory):
        print(f"âš ï¸ ç›®å½• '{directory}' ä¸å­˜åœ¨ã€‚")
        return all_words

    # os.walk å¯ä»¥ç©¿é€å­æ–‡ä»¶å¤¹
    for root, dirs, files in os.walk(directory):
        for filename in files:
            if filename.endswith('.json'):
                file_path = os.path.join(root, filename)
                file_count += 1
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        # é€’å½’æå–å½“å‰æ–‡ä»¶ä¸­çš„å•è¯
                        deep_extract_words(data, all_words)
                except Exception as e:
                    # æ‰“å°å‡ºé”™çš„æ–‡ä»¶åï¼Œæ–¹ä¾¿æ’æŸ¥
                    print(f"âš ï¸ è¯»å–æ–‡ä»¶å‡ºé”™: {file_path} -> {e}")

    print(f"ğŸ“‚ å·²æ‰«æ {file_count} ä¸ª JSON æ–‡ä»¶ã€‚")
    return all_words

def main():
    print("ğŸš€ å¼€å§‹å¤„ç†...")

    # 1. å¤„ç† A æ•°ç»„
    list_a = extract_json_from_md(SOURCE_FILE)
    set_a = set(w.strip().lower() for w in list_a)
    print(f"âœ… A æ•°ç»„ (middle.md) æå–åˆ°: {len(set_a)} ä¸ªå”¯ä¸€å•è¯")

    # 2. å¤„ç† B æ•°ç»„
    list_b = load_words_from_directory_recursive(FILTER_DIR)
    set_b = set(w.strip().lower() for w in list_b)
    print(f"âœ… B æ•°ç»„ (ç›®å½•ä¸­æ‰€æœ‰json) æå–åˆ°: {len(set_b)} ä¸ªå”¯ä¸€å•è¯")

    if len(set_b) == 0:
        print("âš ï¸ è­¦å‘Š: Bæ•°ç»„ä¾ç„¶ä¸ºç©ºï¼è¯·æ£€æŸ¥ json æ–‡ä»¶å†…å®¹æ ¼å¼ï¼Œæˆ–è€…æ˜¯å¦çœŸçš„åŒ…å«å•è¯ã€‚")

    # 3. å·®é›†è¿ç®—
    result_set = set_a - set_b
    result_list = sorted(list(result_set))

    print("-" * 40)
    print(f"ğŸ“Š ç»Ÿè®¡ç»“æœ:")
    print(f"   A åŸæœ‰: {len(set_a)}")
    print(f"   B æ’é™¤: {len(set_b)}")
    print(f"   å‰©ä½™  : {len(result_list)}")
    print("-" * 40)

    # 4. è¾“å‡º
    if result_list:
        with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
            f.write(f"--- å‰©ä½™å•è¯ ({len(result_list)}) ---\n")
            for word in result_list:
                f.write(word + '\n')
        print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜è‡³: {OUTPUT_FILE}")
    else:
        print("â­• ç»“æœä¸ºç©ºï¼ŒAä¸­çš„æ‰€æœ‰å•è¯å‡åœ¨Bä¸­ã€‚")

if __name__ == "__main__":
    main()