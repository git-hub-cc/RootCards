# -*- coding: utf-8 -*-
"""
Etymology Visualizer éŸ³é¢‘ç¼“å­˜ç”Ÿæˆè„šæœ¬

åŠŸèƒ½:
1. è‡ªåŠ¨è¯»å– `js/data-manifest.js` æ–‡ä»¶ï¼Œè·å–æ‰€æœ‰å•è¯æ•°æ®æºã€‚
2. è§£æ JSON æ•°æ®æ–‡ä»¶ï¼Œæå–æ‰€æœ‰å”¯ä¸€çš„å•è¯å’Œä¾‹å¥ã€‚
3. ä½¿ç”¨ Google Text-to-Speech (gTTS) æœåŠ¡ï¼Œä¸ºæ¯ä¸ªå•è¯å’Œä¾‹å¥ç”Ÿæˆå¯¹åº”çš„è‹±æ–‡å‘éŸ³ MP3 æ–‡ä»¶ã€‚
4. å°†ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶ä¿å­˜åˆ° `audio/words` å’Œ `audio/sentences` ç›®å½•ä¸­ã€‚
5. [æ ¸å¿ƒ] è„šæœ¬å…·æœ‰ç¼“å­˜æ£€æŸ¥åŠŸèƒ½ï¼šå¦‚æœéŸ³é¢‘æ–‡ä»¶å·²å­˜åœ¨ä¸”æœ‰æ•ˆï¼Œåˆ™ä¼šè·³è¿‡ï¼Œå¤§å¤§æé«˜äºŒæ¬¡è¿è¡Œçš„é€Ÿåº¦ã€‚

ä½¿ç”¨æ–¹æ³•:
1. ç¡®ä¿å·²å®‰è£… Python 3 å’Œå¿…è¦çš„åº“:
   pip install gtts mutagen
2. å°†æ­¤è„šæœ¬æ”¾ç½®åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹ã€‚
3. åœ¨ç»ˆç«¯ä¸­è¿è¡Œæ­¤è„šæœ¬:
   python generate_audio.py
"""

import os
import json
import re
import time
from pathlib import Path
from gtts import gTTS
from mutagen.mp3 import MP3, HeaderNotFoundError

# --- é…ç½®åŒºåŸŸ ---

# æ•°æ®æ¸…å•æ–‡ä»¶çš„è·¯å¾„
MANIFEST_PATH = Path("js/data-manifest.js")
# JSON æ•°æ®æ–‡ä»¶æ‰€åœ¨çš„æ ¹ç›®å½•
DATA_ROOT = Path("data")
# éŸ³é¢‘æ–‡ä»¶è¾“å‡ºçš„æ ¹ç›®å½•
AUDIO_ROOT = Path("audio")
# å•è¯éŸ³é¢‘è¾“å‡ºç›®å½•
WORDS_DIR = AUDIO_ROOT / "words"
# ä¾‹å¥éŸ³é¢‘è¾“å‡ºç›®å½•
SENTENCES_DIR = AUDIO_ROOT / "sentences"

# æ¯æ¬¡è¯·æ±‚ gTTS API åçš„å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé¿å…å› è¯·æ±‚è¿‡å¿«è¢«æœåŠ¡å™¨å°ç¦
REQUEST_DELAY = 0.5
# ç”¨äºåˆ¤æ–­ç°æœ‰æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆçš„æœ€å°æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰ã€‚å°äºæ­¤å€¼çš„æ–‡ä»¶å°†è¢«è§†ä¸ºæ— æ•ˆå¹¶é‡æ–°ç”Ÿæˆã€‚
MIN_FILE_SIZE_BYTES = 1024  # 1 KB

# --- è„šæœ¬æ ¸å¿ƒé€»è¾‘ ---

def parse_manifest(manifest_path: Path) -> list[Path]:
    """
    è§£æ data-manifest.js æ–‡ä»¶ï¼Œæå–å…¶ä¸­ DATA_FILES æ•°ç»„ä¸­çš„æ‰€æœ‰ JSON æ–‡ä»¶è·¯å¾„ã€‚

    Args:
        manifest_path: data-manifest.js çš„è·¯å¾„å¯¹è±¡ã€‚

    Returns:
        ä¸€ä¸ªåŒ…å«æ‰€æœ‰æ•°æ®æ–‡ä»¶ç»å¯¹è·¯å¾„çš„åˆ—è¡¨ã€‚
    """
    print(f"ğŸ“„ æ­£åœ¨è§£ææ•°æ®æ¸…å•: {manifest_path}")
    if not manifest_path.exists():
        print(f"âŒ é”™è¯¯: æœªæ‰¾åˆ°æ•°æ®æ¸…å•æ–‡ä»¶ '{manifest_path}'ã€‚è¯·ç¡®ä¿è„šæœ¬ä½ç½®æ­£ç¡®ã€‚")
        return []

    try:
        content = manifest_path.read_text(encoding='utf-8')
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é… DATA_FILES æ•°ç»„çš„å†…å®¹
        match = re.search(r"const DATA_FILES\s*=\s*\[(.*?)\];", content, re.DOTALL)
        if not match:
            print(f"âŒ é”™è¯¯: æ— æ³•åœ¨ '{manifest_path}' ä¸­æ‰¾åˆ° 'DATA_FILES' æ•°ç»„ã€‚")
            return []

        # æå–æ•°ç»„å†…å®¹ï¼Œå»é™¤æ³¨é‡Šã€ç©ºæ ¼å’Œå¼•å·ï¼Œå¹¶è¿‡æ»¤ç©ºè¡Œ
        file_paths_str = match.group(1)
        # ç§»é™¤è¡Œæ³¨é‡Š
        file_paths_str = re.sub(r'//.*', '', file_paths_str)
        # æå–å¼•å·å†…çš„è·¯å¾„
        paths = [p.strip() for p in re.findall(r"['\"](.*?)['\"]", file_paths_str)]

        # è½¬æ¢ä¸º Path å¯¹è±¡
        absolute_paths = [Path(p) for p in paths if p]
        print(f"   - æˆåŠŸæ‰¾åˆ° {len(absolute_paths)} ä¸ªæ•°æ®æ–‡ä»¶ã€‚")
        return absolute_paths
    except Exception as e:
        print(f"âŒ é”™è¯¯: è§£ææ¸…å•æ–‡ä»¶æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}")
        return []


def aggregate_data(file_paths: list[Path]) -> tuple[set[str], dict[str, str]]:
    """
    éå†æ‰€æœ‰æ•°æ®æ–‡ä»¶ï¼Œèšåˆæ‰€æœ‰å”¯ä¸€çš„å•è¯å’Œä¾‹å¥ã€‚

    Args:
        file_paths: æ•°æ®æ–‡ä»¶çš„è·¯å¾„åˆ—è¡¨ã€‚

    Returns:
        ä¸€ä¸ªå…ƒç»„ï¼ŒåŒ…å«:
        - unique_words (set): æ‰€æœ‰å”¯ä¸€å•è¯çš„å°å†™é›†åˆã€‚
        - unique_sentences (dict): {ä¾‹å¥: å¯¹åº”å•è¯çš„å°å†™} çš„å­—å…¸ã€‚
    """
    unique_words = set()
    unique_sentences = {}

    print("\nğŸ“¦ æ­£åœ¨èšåˆæ‰€æœ‰å•è¯å’Œä¾‹å¥...")
    for file_path in file_paths:
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if "words" in data and isinstance(data["words"], list):
                    for word_data in data["words"]:
                        word = word_data.get("word")
                        sentence = word_data.get("sentence")
                        if word:
                            word_lower = word.lower()
                            unique_words.add(word_lower)
                            if sentence:
                                # ä½¿ç”¨å­—å…¸ç¡®ä¿æ¯ä¸ªä¾‹å¥åªè¢«æ·»åŠ ä¸€æ¬¡
                                unique_sentences[sentence] = word_lower
        except json.JSONDecodeError:
            print(f"   - [è­¦å‘Š] æ–‡ä»¶ '{file_path}' ä¸æ˜¯æœ‰æ•ˆçš„ JSON æ–‡ä»¶ï¼Œå·²è·³è¿‡ã€‚")
        except FileNotFoundError:
            print(f"   - [è­¦å‘Š] æœªæ‰¾åˆ°æ–‡ä»¶ '{file_path}'ï¼Œå·²è·³è¿‡ã€‚")
        except Exception as e:
            print(f"   - [é”™è¯¯] å¤„ç†æ–‡ä»¶ '{file_path}' æ—¶å‡ºé”™: {e}")

    print(f"   - èšåˆå®Œæˆ: æ‰¾åˆ° {len(unique_words)} ä¸ªç‹¬ç«‹å•è¯ï¼Œ{len(unique_sentences)} æ¡ç‹¬ç«‹ä¾‹å¥ã€‚")
    return unique_words, unique_sentences


def generate_audio_file(text: str, output_path: Path) -> bool:
    """
    ä¸ºç»™å®šçš„æ–‡æœ¬ç”ŸæˆéŸ³é¢‘æ–‡ä»¶ï¼Œå¹¶è¿›è¡Œç¼“å­˜æ£€æŸ¥ã€‚

    Args:
        text: éœ€è¦è½¬æ¢ä¸ºè¯­éŸ³çš„æ–‡æœ¬ã€‚
        output_path: MP3 æ–‡ä»¶çš„è¾“å‡ºè·¯å¾„ã€‚

    Returns:
        True è¡¨ç¤ºæˆåŠŸï¼ˆæˆ–å·²ç¼“å­˜ï¼‰ï¼ŒFalse è¡¨ç¤ºå¤±è´¥ã€‚
    """
    # 1. ç¼“å­˜æ£€æŸ¥ï¼šå¦‚æœæ–‡ä»¶å­˜åœ¨ä¸”æœ‰æ•ˆï¼Œåˆ™è·³è¿‡
    if output_path.exists() and output_path.stat().st_size >= MIN_FILE_SIZE_BYTES:
        try:
            # ä½¿ç”¨ mutagen å°è¯•è¯»å–æ–‡ä»¶ï¼ŒéªŒè¯å…¶ä¸ºæœ‰æ•ˆçš„ MP3
            MP3(output_path)
            # print(f"  [è·³è¿‡] '{output_path.name}' å·²å­˜åœ¨ä¸”æœ‰æ•ˆã€‚")
            return True
        except HeaderNotFoundError:
            print(f"  [è­¦å‘Š] '{output_path.name}' å·²å­˜åœ¨ä½†æ–‡ä»¶æŸåï¼Œå°†é‡æ–°ç”Ÿæˆã€‚")
        except Exception as e:
            print(f"  [è­¦å‘Š] æ£€æŸ¥ '{output_path.name}' æ—¶å‡ºé”™ ({e})ï¼Œå°†é‡æ–°ç”Ÿæˆã€‚")

    # 2. ç”Ÿæˆæ–‡ä»¶
    try:
        print(f"  [ç”Ÿæˆ] æ­£åœ¨è¯·æ±‚ '{output_path.name}'...")
        tts = gTTS(text=text, lang='en', slow=False)
        tts.save(str(output_path))  # gTTS çš„ save æ–¹æ³•éœ€è¦å­—ç¬¦ä¸²è·¯å¾„
        # print(f"  [æˆåŠŸ] å·²ä¿å­˜ '{output_path.name}'")
        time.sleep(REQUEST_DELAY)  # ç¤¼è²Œæ€§å»¶è¿Ÿ
        return True
    except AssertionError:
        # gTTS åœ¨æ²¡æœ‰æ–‡æœ¬æ—¶ä¼šæŠ›å‡º AssertionError
        print(f"  [é”™è¯¯] æ–‡æœ¬ä¸ºç©ºï¼Œæ— æ³•ä¸º '{output_path.name}' ç”ŸæˆéŸ³é¢‘ã€‚")
        return False
    except Exception as e:
        print(f"  [ä¸¥é‡é”™è¯¯] ç”Ÿæˆ '{output_path.name}' å¤±è´¥: {e}")
        # å¦‚æœç”Ÿæˆå¤±è´¥ï¼Œåˆ é™¤å¯èƒ½å·²åˆ›å»ºçš„ç©ºæ–‡ä»¶æˆ–æŸåæ–‡ä»¶
        if output_path.exists():
            output_path.unlink()
        return False


def main():
    """è„šæœ¬ä¸»æ‰§è¡Œå‡½æ•°"""
    print("=" * 50)
    print("ğŸš€ å¼€å§‹æ‰§è¡Œ Etymology Visualizer éŸ³é¢‘ç¼“å­˜ç”Ÿæˆè„šæœ¬ ğŸš€")
    print("=" * 50)

    # 1. ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    WORDS_DIR.mkdir(parents=True, exist_ok=True)
    SENTENCES_DIR.mkdir(parents=True, exist_ok=True)
    print(f"âœ… è¾“å‡ºç›®å½•å·²å‡†å¤‡å°±ç»ª:\n   - å•è¯: {WORDS_DIR}\n   - ä¾‹å¥: {SENTENCES_DIR}")

    # 2. è§£ææ¸…å•å¹¶èšåˆæ•°æ®
    data_files = parse_manifest(MANIFEST_PATH)
    if not data_files:
        print("\nâŒ æœªèƒ½ä»æ¸…å•ä¸­è·å–ä»»ä½•æ•°æ®æ–‡ä»¶ï¼Œè„šæœ¬ç»ˆæ­¢ã€‚")
        return

    words, sentences = aggregate_data(data_files)
    if not words and not sentences:
        print("\nâŒ æœªèƒ½ä»æ•°æ®æ–‡ä»¶ä¸­èšåˆä»»ä½•å•è¯æˆ–ä¾‹å¥ï¼Œè„šæœ¬ç»ˆæ­¢ã€‚")
        return

    # --- å¼€å§‹ç”Ÿæˆå•è¯éŸ³é¢‘ ---
    print("\n" + "-" * 20)
    print(f"ğŸ¤ å¼€å§‹å¤„ç† {len(words)} ä¸ªå•è¯éŸ³é¢‘...")
    print("-" * 20)

    success_words, failed_words = 0, 0
    # æ’åºä»¥ä¿è¯æ¯æ¬¡è¿è¡Œé¡ºåºä¸€è‡´
    for i, word in enumerate(sorted(list(words)), 1):
        print(f"è¿›åº¦: {i}/{len(words)} - å•è¯: '{word}'")
        file_path = WORDS_DIR / f"{word}.mp3"
        if generate_audio_file(word, file_path):
            success_words += 1
        else:
            failed_words += 1

    # --- å¼€å§‹ç”Ÿæˆä¾‹å¥éŸ³é¢‘ ---
    print("\n" + "-" * 20)
    print(f"ğŸ§ å¼€å§‹å¤„ç† {len(sentences)} æ¡ä¾‹å¥éŸ³é¢‘...")
    print("-" * 20)

    success_sentences, failed_sentences = 0, 0
    # æ’åºä»¥ä¿è¯æ¯æ¬¡è¿è¡Œé¡ºåºä¸€è‡´
    sorted_sentences = sorted(sentences.items(), key=lambda item: item[1])
    for i, (sentence, word_key) in enumerate(sorted_sentences, 1):
        # æ–‡ä»¶åä½¿ç”¨å…¶å¯¹åº”çš„å•è¯æ¥å‘½åï¼Œä¸å‰ç«¯é€»è¾‘ä¿æŒä¸€è‡´
        filename = f"{word_key}_sentence.mp3"
        print(f"è¿›åº¦: {i}/{len(sentences)} - ä¾‹å¥ for '{word_key}'")
        file_path = SENTENCES_DIR / filename
        if generate_audio_file(sentence, file_path):
            success_sentences += 1
        else:
            failed_sentences += 1

    # --- æœ€ç»ˆæŠ¥å‘Š ---
    print("\n" + "=" * 50)
    print("ğŸ‰ğŸ‰ğŸ‰ æ‰€æœ‰ä»»åŠ¡æ‰§è¡Œå®Œæ¯•ï¼ğŸ‰ğŸ‰ğŸ‰")
    print("=" * 50)
    print("ğŸ“Š ç”ŸæˆæŠ¥å‘Š:")
    print(f"  - å•è¯éŸ³é¢‘: {success_words} ä¸ªæˆåŠŸ, {failed_words} ä¸ªå¤±è´¥ã€‚")
    print(f"  - ä¾‹å¥éŸ³é¢‘: {success_sentences} ä¸ªæˆåŠŸ, {failed_sentences} ä¸ªå¤±è´¥ã€‚")
    print("\nç°åœ¨æ‚¨çš„ 'audio' æ–‡ä»¶å¤¹å·²æ˜¯æœ€æ–°çŠ¶æ€ã€‚")
    print("=" * 50)


if __name__ == "__main__":
    main()